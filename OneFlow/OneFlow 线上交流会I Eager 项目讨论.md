2020年8月3日晚，OneFlow 在线上进行了第一次有社区朋友参加的会议，由李新奇分享 OneFlow 的分布式并行易用性以及进行中的 Eager 项目，内容主要包括三个部分：

​	-OneFlow 的分布式并行易用性

​	-Eager 的设计

​	-Eager 的性能优化

# OneFlow 的分布式并行易用性

内容提要：

其它深度学习框架对数据并行有比较好的支持，但是 OneFlow 对数据并行、模型并行、模型数据混合并行都有很好的支持而且易用。

分享中展示了2个矩阵乘法，运行在2块 GPU 上：第一个矩阵是 S = A * B，对 A的第0维做切分，对应数据并行；第二个是 S = S * A，对 A 的第1维做切分，对应模型并行；两个矩阵的串联执行，对应数据模型混合并行。通过展示可以看到，只需指定数据切分的维度，便可以自动实现数据并行、模型并行、数据模型混合并行，这些并行依赖的数据切分合并、数据搬运等操作 OneFlow 在框架层面已经自动解决。

# Eager 设计

内容提要：

Eager 是实验性项目，目的是让 OneFlow 能够支持动态计算图，边构图边计算。

通过演示可以看到，只需一行代码打开开关，即可实现动态图，边执行边打印中间结果。不同于其它框架的单机Eager执行视角，OneFlow Eager 定位支持多机多卡 Eager 执行，引入了 Eager 虚拟机，Python 前端接收指令发送给虚拟机，虚拟机来控制发射真正的执行指令，通过这一层抽象，可以支持 SIMD、乱序发射等，实现多机多卡 Eager 执行。

# Eager 性能优化

内容提要：

Eager 的正确性已经基本实现，效率还需优化。当前 Eager 的第二个迭代及之后仍然执行了 Python 前端的 Op 创建、序列化、传输控制等，带来了同第一迭代执行基本重复的开销。计划采用指令、指令块缓存的的设想加以优化，尽量去掉重复的执行开销。